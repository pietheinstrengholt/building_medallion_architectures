{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "639b8111-f233-4ed5-8762-6accc9008beb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fetch parameters from Azure Data Factory\n",
    "schemaName=dbutils.widgets.get(\"schemaName\")\n",
    "tableName=dbutils.widgets.get(\"tableName\")\n",
    "filePath=dbutils.widgets.get(\"filePath\")\n",
    "catalogName=\"mycatalog\"\n",
    "\n",
    "# Create database\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS bronze_{schemaName} MANAGED LOCATION \\\n",
    "'abfss://<container>@<torage-account>.dfs.core.windows.net/{schemaName}'\")\n",
    "\n",
    "# Create new external table using latest datetime location\n",
    "ddl_query = f\"\"\"CREATE OR REPLACE TABLE \n",
    "                {catalogName}.bronze_{schemaName}.{tableName} AS\n",
    "                SELECT * FROM\n",
    "                read_files(\n",
    "                    '/Volumes/{catalogName}/volumes/mnt_landing/\n",
    "                    {schemaName}/{filePath}/{tableName}.parquet',\n",
    "                    header => \"True\"\n",
    "                )\"\"\"\n",
    "\n",
    "# Execute query\n",
    "spark.sql(ddl_query)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Migrating_parquet_to_managed",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}