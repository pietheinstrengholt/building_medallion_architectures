{"cells":[{"cell_type":"code","source":["from pyspark.sql.types import *\n","\n","# Create the schema\n","spark.sql(f'CREATE SCHEMA IF NOT EXISTS adventureworks')\n","\n","# Define the schema for address\n","schemaAddress = StructType([\n","    StructField(\"ID\", StringType()),\n","    StructField(\"AddressID\", IntegerType()),\n","    StructField(\"AddressLine1\", StringType()),\n","    StructField(\"AddressLine2\", StringType()),\n","    StructField(\"City\", StringType()),\n","    StructField(\"StateProvince\", StringType()),\n","    StructField(\"CountryRegion\", StringType()),\n","    StructField(\"current_flag\", BooleanType()),\n","    StructField(\"current_date\", DateType()),\n","    StructField(\"end_date\", DateType())\n","])\n","\n","# Create the DataFrame\n","dfAddress = spark.createDataFrame([], schemaAddress)\n","\n","# Create the table\n","dfAddress.write.mode(\"append\").saveAsTable(\"adventureworks.dimension_address\")\n","\n","# Define the schema for customer\n","schemaCustomer = StructType([\n","    StructField(\"ID\", StringType()),\n","    StructField(\"CustomerID\", IntegerType()),\n","    StructField(\"Title\", StringType()),\n","    StructField(\"FirstName\", StringType()),\n","    StructField(\"MiddleName\", StringType()),\n","    StructField(\"LastName\", StringType()),\n","    StructField(\"CompanyName\", StringType()),\n","    StructField(\"EmailAddress\", StringType()),\n","    StructField(\"Phone\", StringType()),\n","    StructField(\"current_flag\", BooleanType()),\n","    StructField(\"current_date\", DateType()),\n","    StructField(\"end_date\", DateType())\n","])\n","\n","# Create the DataFrame\n","dfCustomer = spark.createDataFrame([], schemaCustomer)\n","\n","# Create the table\n","dfCustomer.write.mode(\"append\").saveAsTable(\"adventureworks.dimension_customer\")\n","\n","# Define the schema for date\n","schemaDate = StructType([\n","    StructField(\"ID\", StringType()),\n","    StructField(\"OrderDate\", DateType()),\n","    StructField(\"Day\", IntegerType()),\n","    StructField(\"Month\", IntegerType()),\n","    StructField(\"Year\", IntegerType())\n","])\n","\n","# Create the DataFrame\n","dfDate = spark.createDataFrame([], schemaDate)\n","\n","# Create the table\n","dfDate.write.mode(\"append\").saveAsTable(\"adventureworks.dimension_date\")\n","\n","# Define the schema for product\n","schemaProduct = StructType([\n","    StructField(\"ID\", StringType()),\n","    StructField(\"ProductID\", IntegerType()),\n","    StructField(\"ProductNumber\", StringType()),\n","    StructField(\"Color\", StringType()),\n","    StructField(\"Size\", StringType()),\n","    StructField(\"Weight\", StringType()),\n","    StructField(\"CategoryName\", StringType()),\n","    StructField(\"ProductModelName\", StringType()),\n","    StructField(\"current_flag\", BooleanType()),\n","    StructField(\"current_date\", DateType()),\n","    StructField(\"end_date\", DateType())\n","])\n","\n","# Create the DataFrame\n","dfProduct = spark.createDataFrame([], schemaProduct)\n","\n","# Create the table\n","dfProduct.write.mode(\"append\").saveAsTable(\"adventureworks.dimension_product\")\n","\n","# Define the schema for sales\n","schemaSales = StructType([\n","    StructField(\"SalesKey\", StringType()),\n","    StructField(\"AddressKey\", StringType()),\n","    StructField(\"CustomerKey\", StringType()),\n","    StructField(\"ProductKey\", StringType()),\n","    StructField(\"DateKey\", StringType()),\n","    StructField(\"Revenue\", DoubleType()),\n","    StructField(\"OrderQty\", IntegerType()),\n","    StructField(\"UnitPrice\", DoubleType()),\n","    StructField(\"current_flag\", BooleanType()),\n","    StructField(\"current_date\", DateType()),\n","    StructField(\"end_date\", DateType())\n","])\n","\n","# Create the DataFrame\n","dfSales = spark.createDataFrame([], schemaSales)\n","\n","# Create the table\n","dfSales.write.mode(\"append\").saveAsTable(\"adventureworks.fact_sales\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"16e20c64-3521-4e87-8ff8-853f6726d2ae","normalized_state":"finished","queued_time":"2024-12-18T10:52:06.3723607Z","session_start_time":"2024-12-18T10:52:06.963891Z","execution_start_time":"2024-12-18T10:52:17.561379Z","execution_finish_time":"2024-12-18T10:52:32.3481454Z","parent_msg_id":"93ee7403-e857-444c-8602-233a208d417e"},"text/plain":"StatementMeta(, 16e20c64-3521-4e87-8ff8-853f6726d2ae, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"11ea443d-32fd-4beb-b736-44a613d10e7e"}],"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"},"language_group":"synapse_pyspark"},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"notebook_environment":{},"widgets":{},"synapse_widget":{"version":"0.1","state":{}},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"89b49d86-b090-4126-b03c-263e6f504321"}],"default_lakehouse":"89b49d86-b090-4126-b03c-263e6f504321","default_lakehouse_name":"Gold","default_lakehouse_workspace_id":"30950d63-22f3-4d65-8813-310477df47b4"}}},"nbformat":4,"nbformat_minor":5}